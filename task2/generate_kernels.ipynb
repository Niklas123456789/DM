{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von generate_kernels.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niklas123456789/DM/blob/main/task2/generate_kernels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VxEwG3kUGD08",
        "outputId": "523bb389-27fd-4acc-900c-a1701badf129"
      },
      "source": [
        "#preinstalled version of pytorch has to be the same as the pre-compiled versions of the pytorch-geometric packages that we download later on.\r\n",
        "#versions might change quickly, so if you get a strange error later on, check the torch version of Google colab later on as follows:\r\n",
        "\r\n",
        "import torch\r\n",
        "torch.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-VN1RcQBUvc",
        "outputId": "e9cd2053-c2dc-4d6f-eff0-ddb55f6f5ddd"
      },
      "source": [
        "# Script to generate variations of the kernels yourself\n",
        "# https://ucloud.univie.ac.at/index.php/s/E3YKph0jkpbw8TN\n",
        "\n",
        "\n",
        "# #Download the TUDataset Repository with\n",
        "!git clone https://github.com/chrsmrrs/tudataset.git\n",
        "# #move this script to tudataset/tud_benchmark\n",
        "\n",
        "# #Install pytorch geometric: https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
        "# #Here is the gpu cuda installation, for the cpu version replace cu102 with cpu\n",
        "%pip --no-cache-dir install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-geometric\n",
        "\n",
        "%pip --no-cache-dir install networkit\n",
        "\n",
        "%pip --no-cache-dir install pybind11\n",
        "!sudo apt-get install libeigen3-dev\n",
        "\n",
        "%cd ..\n",
        "%cd /content/tudataset/tud_benchmark/kernel_baselines/\n",
        "! ls\n",
        "! g++ -I /usr/include/eigen3 -O3 -shared -std=c++11 -fPIC `python3 -m pybind11 --includes`  kernel_baselines.cpp src/*cpp -o ../kernel_baselines`python3-config --extension-suffix`\n",
        "%cd ..\n",
        "\n",
        "!ls -al /usr/local/cuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tudataset'...\n",
            "remote: Enumerating objects: 485, done.\u001b[K\n",
            "remote: Counting objects: 100% (485/485), done.\u001b[K\n",
            "remote: Compressing objects: 100% (366/366), done.\u001b[K\n",
            "remote: Total 3344 (delta 244), reused 300 (delta 114), pack-reused 2859\u001b[K\n",
            "Receiving objects: 100% (3344/3344), 8.47 MiB | 17.96 MiB/s, done.\n",
            "Resolving deltas: 100% (2371/2371), done.\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.0.5\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.3MB)\n",
            "\u001b[K     |████████████████████████████████| 24.3MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.19.4)\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.5MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5MB 1.2MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "Successfully installed torch-cluster-1.5.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 3.0MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Collecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/5c/3e95b76321fb14f24cc2ace392075717f645c4632e796ee0db1bc7d17231/torch_geometric-1.6.3.tar.gz (186kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 4.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.19.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.14)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 16.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/78/edadb45c7f26f8fbb99da81feadb561c26bb0393b6c5d1ac200ecdc12d61/ase-3.20.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 15.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (1.0.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (51.0.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 35.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.6.3-cp36-none-any.whl size=322720 sha256=4ac2434d22cda4bd9a06f74773c5edc30142d427f0a46fa2d03f41c341bfd5b1\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hsjlle7w/wheels/6d/47/1e/0af8ce3e21783c3e584c22502011a3367c091694eebc50a971\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.20.1 isodate-0.6.0 rdflib-5.0.0 torch-geometric-1.6.3\n",
            "Collecting networkit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/9c/597bf1194e823733561422cb8b34ab1ba096678ee592e5f046bacd9be7f6/networkit-8.0.tar.gz (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from networkit) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from networkit) (1.19.4)\n",
            "Building wheels for collected packages: networkit\n",
            "  Building wheel for networkit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkit: filename=networkit-8.0-cp36-cp36m-linux_x86_64.whl size=8028712 sha256=98db69128d95db6b03aff1f7ff73f1018027b99917d1bf8c63d61cf2371e3d1f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-16c051zg/wheels/69/43/a6/9f253843afcae8370e0f50964224c2dd84142d0a57be0440dc\n",
            "Successfully built networkit\n",
            "Installing collected packages: networkit\n",
            "Successfully installed networkit-8.0\n",
            "Collecting pybind11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/84/fc9dc13ee536ba5e6b8fd10ce368fea5b738fe394c3b296cde7c9b144a92/pybind11-2.6.1-py2.py3-none-any.whl (188kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 5.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pybind11\n",
            "Successfully installed pybind11-2.6.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  libeigen3-doc libmrpt-dev\n",
            "The following NEW packages will be installed:\n",
            "  libeigen3-dev\n",
            "0 upgraded, 1 newly installed, 0 to remove and 15 not upgraded.\n",
            "Need to get 810 kB of archives.\n",
            "After this operation, 7,128 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libeigen3-dev all 3.3.4-4 [810 kB]\n",
            "Fetched 810 kB in 1s (1,113 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libeigen3-dev.\n",
            "(Reading database ... 145480 files and directories currently installed.)\n",
            "Preparing to unpack .../libeigen3-dev_3.3.4-4_all.deb ...\n",
            "Unpacking libeigen3-dev (3.3.4-4) ...\n",
            "Setting up libeigen3-dev (3.3.4-4) ...\n",
            "/\n",
            "/content/tudataset/tud_benchmark/kernel_baselines\n",
            "kernel_baselines.cpp  src\n",
            "/content/tudataset/tud_benchmark\n",
            "lrwxrwxrwx 1 root root 9 Dec 21 17:24 /usr/local/cuda -> cuda-10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8HOSZDPBbNV"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import kernel_baselines as kb\n",
        "import auxiliarymethods\n",
        "import auxiliarymethods.auxiliary_methods as aux\n",
        "import auxiliarymethods.kernel_evaluation as ke\n",
        "import auxiliarymethods.datasets as dp\n",
        "from scipy.sparse import save_npz\n",
        "from itertools import combinations\n",
        "\n",
        "import networkit as nk\n",
        "import networkx as nx\n",
        "from auxiliarymethods.reader import tud_to_networkx"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pq17mvdBdym"
      },
      "source": [
        "def setup_directory(dir_name, verbose=False):\n",
        "    \"\"\"\n",
        "    Setup directory in case it does not exist\n",
        "    Parameters:\n",
        "    -------------\n",
        "    dir_name: str, path + name to directory\n",
        "    verbose: bool, indicates whether directory creation should be printed or not.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir_name):\n",
        "        try:\n",
        "            os.makedirs(dir_name)\n",
        "            if verbose:\n",
        "                print(\"Created Directory: {}\".format(dir_name))\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(\n",
        "                \"Could not create directory: {}\\n {}\".format(dir_name, e))\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoWVqxq5B8RW"
      },
      "source": [
        "use_edge_labels = False\n",
        "for USE_LABELS in [True, False]:# Except IMDB-BINARY\n",
        "    break\n",
        "    for dataset, use_labels in [[\"IMDB-BINARY\", False],[\"MSRC_21\",USE_LABELS], [\"NCI1\", USE_LABELS], [\"ENZYMES\", USE_LABELS]]:\n",
        "        if use_labels:\n",
        "            base_path = os.path.join(\"kernels\",\"node_labels\")\n",
        "        else:\n",
        "            base_path = os.path.join(\"kernels\",\"without_labels\")\n",
        "        setup_directory(base_path)\n",
        "        print(\"Start processing data set \", dataset)\n",
        "        # Download dataset.\n",
        "        classes = dp.get_dataset(dataset)\n",
        "        # *Weisfeihler-Lehman*\n",
        "        print(\"Start computing Weisfeihler-Lehman gram matrix and vector representations\")\n",
        "        iterations = 6\n",
        "        #0 taking just the nodelabels themselves into account; \n",
        "        #1 considers nearest-neighbours, 2 one layer deeper and so on\n",
        "        for i in range(1, iterations):\n",
        "            print(\"Start iteration \", i)\n",
        "            #Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
        "            gram_matrix_wl = kb.compute_wl_1_dense(dataset, i, use_labels, use_edge_labels)\n",
        "            np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{i}.csv\"),\n",
        "                    gram_matrix_wl,\n",
        "                    delimiter=\";\")\n",
        "            #Sparse Vectors for the Weisfeiler-Lehmann subtree kernel\n",
        "            vectors_wl = kb.compute_wl_1_sparse(dataset, i, use_labels, use_edge_labels)\n",
        "            save_npz(os.path.join(base_path,f\"{dataset}_vectors_wl{i}.npz\"),\n",
        "                    vectors_wl, compressed=True)\n",
        "\n",
        "        # *Graphlet kernel*\n",
        "        print(\"Start computing Graphlet gram matrix\")\n",
        "\n",
        "        #Gram Matrix for the Graphlet kernel\n",
        "        gram_matrix_graphlet= kb.compute_graphlet_dense(dataset, use_labels, use_edge_labels)\n",
        "        np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_graphlet.csv\"),\n",
        "                gram_matrix_graphlet,\n",
        "                delimiter=\";\")\n",
        "\n",
        "        print(\"Start computing Graphlet vector representation\")\n",
        "        #Sparse Vectors for the Graphlet kernel\n",
        "        vectors_graphlet = kb.compute_graphlet_sparse(dataset, use_labels, use_edge_labels)\n",
        "        save_npz(os.path.join(base_path,f\"{dataset}_vectors_graphlet.npz\"),\n",
        "                vectors_graphlet, compressed=True)\n",
        "\n",
        "\n",
        "        print(\"Start computing Shortest path gram matrix\")\n",
        "\n",
        "        #Gram Matrix for the Shortest path kernel\n",
        "        gram_matrix_shortestpath = kb.compute_shortestpath_dense(dataset, use_labels)\n",
        "        np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_shortestpath.csv\"),\n",
        "                gram_matrix_shortestpath,\n",
        "                delimiter=\";\")\n",
        "\n",
        "        print(\"Start computing Shortest path vector representation\")\n",
        "\n",
        "        #Sparse Vectors for the Shortest path kernel\n",
        "        vectors_shortestpath = kb.compute_shortestpath_sparse(dataset, use_labels)\n",
        "        save_npz(os.path.join(base_path,f\"{dataset}_vectors_shortestpath.npz\"),\n",
        "                vectors_shortestpath, compressed=True)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TC7NxDhdFgA"
      },
      "source": [
        "from networkx.algorithms.community import greedy_modularity_communities\r\n",
        "from networkx.algorithms.community.quality import modularity\r\n",
        "\r\n",
        "def check_symmetric(a, rtol=1e-05, atol=1e-08):\r\n",
        "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\r\n",
        "\r\n",
        "def density_list(G):\r\n",
        "  return [2*g.number_of_edges()/(g.number_of_nodes() * (g.number_of_nodes()-1)) for g in G]\r\n",
        "\r\n",
        "def oep(graph):\r\n",
        "    try:\r\n",
        "        return next(nx.optimize_edit_paths(G[0],graph,timeout=0.05))[2]\r\n",
        "    except StopIteration:\r\n",
        "        return np.inf\r\n",
        "\r\n",
        "# simple community modularity kernel\r\n",
        "def community_modularity_kernel(G):\r\n",
        "  comms = [greedy_modularity_communities(g) for g in G]\r\n",
        "  mods = [modularity(g,greedy_modularity_communities(g)) for g in G]\r\n",
        "\r\n",
        "  mat = np.zeros((1000,1000))\r\n",
        "\r\n",
        "  for i in range(1000):\r\n",
        "    for j in range(1000):\r\n",
        "      mat[i,j] = np.minimum(mods[i],mods[j]) / np.maximum(mods[i],mods[j])\r\n",
        "\r\n",
        "  return np.nan_to_num(mat)\r\n",
        "\r\n",
        "# simple kernel from graph densities\r\n",
        "def density_kernel(G):\r\n",
        "  dens = density_list(G)\r\n",
        "  return np.array([dens]).T.dot(np.array([dens]))\r\n",
        "\r\n",
        "def eigencentrality_kernel(G):\r\n",
        "  eigencents = []\r\n",
        "  mat = np.zeros((1000,1000))\r\n",
        "  \r\n",
        "  for g in G:\r\n",
        "    vals = nx.eigenvector_centrality(g)\r\n",
        "    eigencents.append(np.array([sorted(vals.values(),reverse=True)[:5]]))\r\n",
        "  \r\n",
        "  for i in range(1000):\r\n",
        "    for j in range(i,1000):\r\n",
        "      mat[i,j] = eigencents[i].dot(eigencents[j].T)\r\n",
        "  \r\n",
        "  return np.maximum(mat, mat.T)\r\n",
        "\r\n",
        "def isomorphism_kernel(G):\r\n",
        "    '''\r\n",
        "    This function returns the number of isomorphic pairs of a network with several ego-graphs.\r\n",
        "    '''\r\n",
        "    iso = np.diag(np.full(len(G),1)) # graphs are always isomorphic to themselves\r\n",
        "\r\n",
        "    for i in range(1, 1000):\r\n",
        "      for j in range(i+1,1000):\r\n",
        "        iso[i,j] = np.where(nx.faster_could_be_isomorphic(G[i], G[j]),1,0)\r\n",
        "    return np.maximum(iso, iso.T)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDc6FzcRf_5U"
      },
      "source": [
        "dataset = \"IMDB-BINARY\"\r\n",
        "classes = dp.get_dataset(dataset)\r\n",
        "G = tud_to_networkx(dataset)\r\n",
        "nkG = [nk.nxadapter.nx2nk(g) for g in G]\r\n",
        "\r\n",
        "def eval(matrices):\r\n",
        "  accuracy, std_10, std_100 = ke.kernel_svm_evaluation(matrices, classes, num_repetitions=num_reps, all_std=True)\r\n",
        "  print(accuracy, std_10, std_100)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwmivzKMe6yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e0f3ad-6a45-45f1-8cb4-43f02b6c21f4"
      },
      "source": [
        "all_kernels = []\r\n",
        "num_reps = 10\r\n",
        "all_kernels.append(density_kernel(G))\r\n",
        "all_kernels.append(community_modularity_kernel(G))\r\n",
        "# print(accuracy, std_10, std_100) == (57.489999999999995, 1.2061923561356205, 5.356295361534873) # density, community\r\n",
        "\r\n",
        "eval(all_kernels)\r\n",
        "all_kernels.append(isomorphism_kernel(G))\r\n",
        "eval(all_kernels)\r\n",
        "# print(accuracy, std_10, std_100) == (59.03000000000001 1.8947559209565754 5.689384852512616) # density, community, isomorphic\r\n",
        "all_kernels.append(density_kernel(G))\r\n",
        "eval(all_kernels)\r\n",
        "# print(accuracy, std_10, std_100) == (62.17999999999999 1.0505236789335117 4.883400454601282) # density, community, isomorphic, eigencentrality\r\n",
        "all_kernels.append(eigencentrality_kernel(G))\r\n",
        "eval(all_kernels)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "58.06 0.7952358140828414 4.46277940301781\n",
            "59.75 1.3462912017836253 5.6415866562519446\n",
            "60.160000000000004 1.4602739469017447 4.694081379780286\n",
            "62.52 1.2327205684987992 4.788486190854057\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPdcYpCrglTP"
      },
      "source": [
        "Experiments below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zSVWCRyd749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe996248-c357-4504-f163-9d08d3afd718"
      },
      "source": [
        "all_matrices = []\r\n",
        "num_reps = 10\r\n",
        "use_labels, use_edge_labels = False, False\r\n",
        "\r\n",
        "# 1-WL kernel, number of iterations in [1:6].\r\n",
        "for i in range(1,6):\r\n",
        "    gm = kb.compute_wl_1_dense(dataset, i, use_labels, use_edge_labels)\r\n",
        "    # Cosine normalization.\r\n",
        "    gm = aux.normalize_gram_matrix(gm)\r\n",
        "    all_matrices.append(gm)\r\n",
        "    print(gm.shape)\r\n",
        "    print(gm[:5,:5])\r\n",
        "\r\n",
        "# accuracy is a mean of means of test accuracies\r\n",
        "accuracy, std_10, std_100 = ke.kernel_svm_evaluation(all_matrices, classes, num_repetitions=num_reps, all_std=True)\r\n",
        "print(accuracy, std_10, std_100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 1000)\n",
            "[[1.         0.09855258 0.08595703 0.22520897 0.13533299]\n",
            " [0.09855258 1.         0.07596444 0.2003595  0.04272494]\n",
            " [0.08595703 0.07596444 1.         0.21237361 0.05681146]\n",
            " [0.22520897 0.2003595  0.21237361 1.         0.10203572]\n",
            " [0.13533299 0.04272494 0.05681146 0.10203572 1.        ]]\n",
            "71.96000000000001 0.798999374217527 4.28933561288925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qkYqXZoA5UV",
        "outputId": "b585050b-4153-4ee0-ff89-1fe3e0158e78"
      },
      "source": [
        "G1 = nx.cycle_graph(6)\r\n",
        "G2 = nx.wheel_graph(7)\r\n",
        "nx.graph_edit_distance(G2, G1)\r\n",
        "\r\n",
        "import time\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "for g1 in range(5):\r\n",
        "  for g2 in range(5):\r\n",
        "    gen = nx.optimize_edit_paths(G[g1],G[g2],timeout=0.05)\r\n",
        "\r\n",
        "    try:\r\n",
        "      print(next(gen)[2])\r\n",
        "    except StopIteration:\r\n",
        "      pass\r\n",
        "      \r\n",
        "print(time.time() - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.0\n",
            "185.0\n",
            "97.0\n",
            "185.0\n",
            "91.0\n",
            "185.0\n",
            "180.0\n",
            "190.0\n",
            "105.0\n",
            "184.0\n",
            "102.0\n",
            "190.0\n",
            "94.0\n",
            "173.0\n",
            "190.0\n",
            "184.0\n",
            "93.0\n",
            "190.0\n",
            "92.0\n",
            "186.0\n",
            "44.0\n",
            "0.9439151287078857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S5PwJmbBTjE",
        "outputId": "7e7ba34e-09f5-482b-cac6-ee8c43436fba"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "\r\n",
        "def is_symmetric(a, rtol=1e-05, atol=1e-08):\r\n",
        "    return numpy.allclose(a, a.T, rtol=rtol, atol=atol)\r\n",
        "\r\n",
        "dists = np.zeros((1000,1000))\r\n",
        "print(dists.shape)\r\n",
        "\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "dists[0] = [oep(g) for g in G]\r\n",
        "print(time.time()-start)\r\n",
        "\r\n",
        "# for g1 in range(1,len(G)):\r\n",
        "#   print(g1)\r\n",
        "#   for g2 in range(g1,len(G)):\r\n",
        "#     if g1 != g2:\r\n",
        "#       gen = nx.optimize_edit_paths(G[g1],G[g2],timeout=0.05)\r\n",
        "\r\n",
        "#       try:\r\n",
        "#         dists[g1,g2] = next(gen)[2]\r\n",
        "#       except StopIteration:\r\n",
        "#         dists[g1,g2] = np.inf\r\n",
        "\r\n",
        "# print(is_symmetric(dists))\r\n",
        "# ke.kernel_svm_evaluation([dists], classes, num_repetitions=num_reps, all_std=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 1000)\n",
            "24.982826709747314\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}