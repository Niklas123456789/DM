{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von generate_kernels.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Niklas123456789/DM/blob/main/task2/generate_kernels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VxEwG3kUGD08",
        "outputId": "7c787d3e-560f-4339-f44d-6090ad459cbc"
      },
      "source": [
        "#preinstalled version of pytorch has to be the same as the pre-compiled versions of the pytorch-geometric packages that we download later on.\r\n",
        "#versions might change quickly, so if you get a strange error later on, check the torch version of Google colab later on as follows:\r\n",
        "\r\n",
        "import torch\r\n",
        "torch.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.7.0+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-VN1RcQBUvc",
        "outputId": "ae0f1ff9-2479-4fed-b654-0c7659046822"
      },
      "source": [
        "# Script to generate variations of the kernels yourself\n",
        "# https://ucloud.univie.ac.at/index.php/s/E3YKph0jkpbw8TN\n",
        "\n",
        "\n",
        "# #Download the TUDataset Repository with\n",
        "!git clone https://github.com/chrsmrrs/tudataset.git\n",
        "# #move this script to tudataset/tud_benchmark\n",
        "\n",
        "# #Install pytorch geometric: https://pytorch-geometric.readthedocs.io/en/latest/notes/installation.html\n",
        "# #Here is the gpu cuda installation, for the cpu version replace cu102 with cpu\n",
        "%pip --no-cache-dir install torch-scatter==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-sparse==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-cluster==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-spline-conv==latest+cu101 -f https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
        "%pip --no-cache-dir install torch-geometric\n",
        "\n",
        "%pip --no-cache-dir install networkit\n",
        "\n",
        "%pip --no-cache-dir install pybind11\n",
        "!sudo apt-get install libeigen3-dev\n",
        "\n",
        "%cd ..\n",
        "%cd /content/tudataset/tud_benchmark/kernel_baselines/\n",
        "! ls\n",
        "! g++ -I /usr/include/eigen3 -O3 -shared -std=c++11 -fPIC `python3 -m pybind11 --includes`  kernel_baselines.cpp src/*cpp -o ../kernel_baselines`python3-config --extension-suffix`\n",
        "%cd ..\n",
        "\n",
        "!ls -al /usr/local/cuda"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'tudataset'...\n",
            "remote: Enumerating objects: 485, done.\u001b[K\n",
            "remote: Counting objects: 100% (485/485), done.\u001b[K\n",
            "remote: Compressing objects: 100% (366/366), done.\u001b[K\n",
            "remote: Total 3344 (delta 244), reused 300 (delta 114), pack-reused 2859\u001b[K\n",
            "Receiving objects: 100% (3344/3344), 8.47 MiB | 35.99 MiB/s, done.\n",
            "Resolving deltas: 100% (2371/2371), done.\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-scatter==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_scatter-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 57.5MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-scatter\n",
            "  Found existing installation: torch-scatter 2.0.5\n",
            "    Uninstalling torch-scatter-2.0.5:\n",
            "      Successfully uninstalled torch-scatter-2.0.5\n",
            "Successfully installed torch-scatter-2.0.5\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-sparse==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_sparse-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (24.3MB)\n",
            "\u001b[K     |████████████████████████████████| 24.3MB 1.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-sparse==latest+cu101) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy->torch-sparse==latest+cu101) (1.19.5)\n",
            "Installing collected packages: torch-sparse\n",
            "  Found existing installation: torch-sparse 0.6.8\n",
            "    Uninstalling torch-sparse-0.6.8:\n",
            "      Successfully uninstalled torch-sparse-0.6.8\n",
            "Successfully installed torch-sparse-0.6.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-cluster==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_cluster-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (21.5MB)\n",
            "\u001b[K     |████████████████████████████████| 21.5MB 1.2MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-cluster\n",
            "  Found existing installation: torch-cluster 1.5.8\n",
            "    Uninstalling torch-cluster-1.5.8:\n",
            "      Successfully uninstalled torch-cluster-1.5.8\n",
            "Successfully installed torch-cluster-1.5.8\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.7.0.html\n",
            "Collecting torch-spline-conv==latest+cu101\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.7.0/torch_spline_conv-latest%2Bcu101-cp36-cp36m-linux_x86_64.whl (6.4MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4MB 41.3MB/s \n",
            "\u001b[?25hInstalling collected packages: torch-spline-conv\n",
            "  Found existing installation: torch-spline-conv 1.2.0\n",
            "    Uninstalling torch-spline-conv-1.2.0:\n",
            "      Successfully uninstalled torch-spline-conv-1.2.0\n",
            "Successfully installed torch-spline-conv-1.2.0\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.6/dist-packages (1.6.3)\n",
            "Requirement already satisfied: ase in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (3.20.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.11.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.48.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (5.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (1.7.0+cu101)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.6/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->torch-geometric) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->torch-geometric) (51.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->torch-geometric) (1.0.0)\n",
            "Requirement already satisfied: isodate in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (0.6.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torch-geometric) (0.8)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Collecting networkit\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/9c/597bf1194e823733561422cb8b34ab1ba096678ee592e5f046bacd9be7f6/networkit-8.0.tar.gz (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 11.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from networkit) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from networkit) (1.19.5)\n",
            "Building wheels for collected packages: networkit\n",
            "  Building wheel for networkit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for networkit: filename=networkit-8.0-cp36-cp36m-linux_x86_64.whl size=8028494 sha256=8770da807ba16f601cce96a74a23e03df24a38622f25c3ed88538aa368e90504\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-xqw5i3wa/wheels/69/43/a6/9f253843afcae8370e0f50964224c2dd84142d0a57be0440dc\n",
            "Successfully built networkit\n",
            "Installing collected packages: networkit\n",
            "Successfully installed networkit-8.0\n",
            "Requirement already satisfied: pybind11 in /usr/local/lib/python3.6/dist-packages (2.6.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libeigen3-dev is already the newest version (3.3.4-4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 16 not upgraded.\n",
            "/content/tudataset\n",
            "/content/tudataset/tud_benchmark/kernel_baselines\n",
            "kernel_baselines.cpp  src\n",
            "/content/tudataset/tud_benchmark\n",
            "lrwxrwxrwx 1 root root 9 Jan  6 18:04 /usr/local/cuda -> cuda-10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8HOSZDPBbNV"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import kernel_baselines as kb\n",
        "import auxiliarymethods\n",
        "import auxiliarymethods.auxiliary_methods as aux\n",
        "import auxiliarymethods.kernel_evaluation as ke\n",
        "import auxiliarymethods.datasets as dp\n",
        "from scipy.sparse import save_npz\n",
        "from itertools import combinations\n",
        "\n",
        "import networkit as nk\n",
        "import networkx as nx\n",
        "from networkx.algorithms import approximation as nx_approximation\n",
        "from auxiliarymethods.reader import tud_to_networkx"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pq17mvdBdym"
      },
      "source": [
        "def setup_directory(dir_name, verbose=False):\n",
        "    \"\"\"\n",
        "    Setup directory in case it does not exist\n",
        "    Parameters:\n",
        "    -------------\n",
        "    dir_name: str, path + name to directory\n",
        "    verbose: bool, indicates whether directory creation should be printed or not.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(dir_name):\n",
        "        try:\n",
        "            os.makedirs(dir_name)\n",
        "            if verbose:\n",
        "                print(\"Created Directory: {}\".format(dir_name))\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(\n",
        "                \"Could not create directory: {}\\n {}\".format(dir_name, e))\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoWVqxq5B8RW"
      },
      "source": [
        "use_edge_labels = False\n",
        "for USE_LABELS in [True, False]:# Except IMDB-BINARY\n",
        "    break\n",
        "    for dataset, use_labels in [[\"IMDB-BINARY\", False],[\"MSRC_21\",USE_LABELS], [\"NCI1\", USE_LABELS], [\"ENZYMES\", USE_LABELS]]:\n",
        "        if use_labels:\n",
        "            base_path = os.path.join(\"kernels\",\"node_labels\")\n",
        "        else:\n",
        "            base_path = os.path.join(\"kernels\",\"without_labels\")\n",
        "        setup_directory(base_path)\n",
        "        print(\"Start processing data set \", dataset)\n",
        "        # Download dataset.\n",
        "        classes = dp.get_dataset(dataset)\n",
        "        # *Weisfeihler-Lehman*\n",
        "        print(\"Start computing Weisfeihler-Lehman gram matrix and vector representations\")\n",
        "        iterations = 6\n",
        "        #0 taking just the nodelabels themselves into account; \n",
        "        #1 considers nearest-neighbours, 2 one layer deeper and so on\n",
        "        for i in range(1, iterations):\n",
        "            print(\"Start iteration \", i)\n",
        "            #Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
        "            gram_matrix_wl = kb.compute_wl_1_dense(dataset, i, use_labels, use_edge_labels)\n",
        "            np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{i}.csv\"),\n",
        "                    gram_matrix_wl,\n",
        "                    delimiter=\";\")\n",
        "            #Sparse Vectors for the Weisfeiler-Lehmann subtree kernel\n",
        "            vectors_wl = kb.compute_wl_1_sparse(dataset, i, use_labels, use_edge_labels)\n",
        "            save_npz(os.path.join(base_path,f\"{dataset}_vectors_wl{i}.npz\"),\n",
        "                    vectors_wl, compressed=True)\n",
        "\n",
        "        # *Graphlet kernel*\n",
        "        print(\"Start computing Graphlet gram matrix\")\n",
        "\n",
        "        #Gram Matrix for the Graphlet kernel\n",
        "        gram_matrix_graphlet= kb.compute_graphlet_dense(dataset, use_labels, use_edge_labels)\n",
        "        np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_graphlet.csv\"),\n",
        "                gram_matrix_graphlet,\n",
        "                delimiter=\";\")\n",
        "\n",
        "        print(\"Start computing Graphlet vector representation\")\n",
        "        #Sparse Vectors for the Graphlet kernel\n",
        "        vectors_graphlet = kb.compute_graphlet_sparse(dataset, use_labels, use_edge_labels)\n",
        "        save_npz(os.path.join(base_path,f\"{dataset}_vectors_graphlet.npz\"),\n",
        "                vectors_graphlet, compressed=True)\n",
        "\n",
        "\n",
        "        print(\"Start computing Shortest path gram matrix\")\n",
        "\n",
        "        #Gram Matrix for the Shortest path kernel\n",
        "        gram_matrix_shortestpath = kb.compute_shortestpath_dense(dataset, use_labels)\n",
        "        np.savetxt(os.path.join(base_path,f\"{dataset}_gram_matrix_shortestpath.csv\"),\n",
        "                gram_matrix_shortestpath,\n",
        "                delimiter=\";\")\n",
        "\n",
        "        print(\"Start computing Shortest path vector representation\")\n",
        "\n",
        "        #Sparse Vectors for the Shortest path kernel\n",
        "        vectors_shortestpath = kb.compute_shortestpath_sparse(dataset, use_labels)\n",
        "        save_npz(os.path.join(base_path,f\"{dataset}_vectors_shortestpath.npz\"),\n",
        "                vectors_shortestpath, compressed=True)\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TC7NxDhdFgA"
      },
      "source": [
        "from networkx.algorithms.community import greedy_modularity_communities\r\n",
        "from networkx.algorithms.community.quality import modularity\r\n",
        "\r\n",
        "def check_symmetric(a, rtol=1e-05, atol=1e-08):\r\n",
        "    return np.allclose(a, a.T, rtol=rtol, atol=atol)\r\n",
        "  \r\n",
        "def normalize(prop_list,max_val,min_val):\r\n",
        "  return [(x - min_val) / (max_val - min_val) for x in prop_list]\r\n",
        "\r\n",
        "# def oep(graph):\r\n",
        "#     try:\r\n",
        "#         return next(nx.optimize_edit_paths(G[0],graph,timeout=0.05))[2]\r\n",
        "#     except StopIteration:\r\n",
        "#         return np.inf\r\n",
        "\r\n",
        "# simple community modularity kernel\r\n",
        "def community_modularity_kernel(G):\r\n",
        "  comms = [greedy_modularity_communities(g) for g in G]\r\n",
        "  mods = [modularity(g,greedy_modularity_communities(g)) for g in G]\r\n",
        "\r\n",
        "  mat = np.zeros((1000,1000))\r\n",
        "\r\n",
        "  for i in range(1000):\r\n",
        "    for j in range(1000):\r\n",
        "      mat[i,j] = np.minimum(mods[i],mods[j]) / np.maximum(mods[i],mods[j])\r\n",
        "\r\n",
        "  return np.nan_to_num(mat)\r\n",
        "\r\n",
        "# simple kernel from graph densities\r\n",
        "def density_kernel(G):\r\n",
        "  dens = [2*g.number_of_edges()/(g.number_of_nodes() * (g.number_of_nodes()-1)) for g in G]\r\n",
        "  return np.array([dens]).T.dot(np.array([dens]))\r\n",
        "\r\n",
        "# eigencentrality kernel\r\n",
        "def eigencentrality_kernel(G,topN=5):\r\n",
        "  eigencents = []\r\n",
        "  mat = np.zeros((1000,1000))\r\n",
        "  \r\n",
        "  for g in G:\r\n",
        "    vals = nx.eigenvector_centrality(g)\r\n",
        "    eigencents.append(np.array([sorted(vals.values(),reverse=True)[:topN]]))\r\n",
        "  \r\n",
        "  for i in range(1000):\r\n",
        "    for j in range(i,1000):\r\n",
        "      mat[i,j] = eigencents[i].dot(eigencents[j].T)\r\n",
        "  \r\n",
        "  return np.maximum(mat, mat.T)\r\n",
        "\r\n",
        "def isomorphism_kernel(G):\r\n",
        "    '''\r\n",
        "    This function returns the number of isomorphic pairs of a network with several ego-graphs.\r\n",
        "    '''\r\n",
        "    iso = np.diag(np.full(len(G),1)) # graphs are always isomorphic to themselves\r\n",
        "\r\n",
        "    for i in range(1, 1000):\r\n",
        "      for j in range(i+1,1000):\r\n",
        "        iso[i,j] = np.where(nx.faster_could_be_isomorphic(G[i], G[j]),1,0)\r\n",
        "    \r\n",
        "    return np.maximum(iso, iso.T)\r\n",
        "\r\n",
        "def isomorphism_kernel_norm(G):\r\n",
        "    '''\r\n",
        "    This function returns the number of isomorphic pairs of a network with several ego-graphs.\r\n",
        "    '''\r\n",
        "    iso = np.diag(np.full(len(G),1)) # graphs are always isomorphic to themselves\r\n",
        "\r\n",
        "    for i in range(1, 1000):\r\n",
        "      for j in range(i+1,1000):\r\n",
        "        iso[i,j] = np.where(nx.faster_could_be_isomorphic(G[i], G[j]),1,0)\r\n",
        "    \r\n",
        "    return np.maximum(iso, iso.T)\r\n",
        "\r\n",
        "# kernel from graph nodes and edges\r\n",
        "def node_edge_kernel(G):\r\n",
        "  vals = [g.number_of_edges()/g.number_of_nodes() for g in G]\r\n",
        "  vals = normalize(vals,max_val=max(vals),min_val=min(vals))\r\n",
        "  mat = np.zeros((1000,1000))\r\n",
        "\r\n",
        "  for i in range(1000):\r\n",
        "    for j in range(i,1000):\r\n",
        "      mat[i,j] = vals[i]*vals[j]\r\n",
        "  \r\n",
        "  return np.maximum(mat, mat.T)\r\n",
        "\r\n",
        "# kernel using the treewidth\r\n",
        "def treewidth_kernel(G):\r\n",
        "  widths = [nx_approximation.treewidth.treewidth_min_degree(g)[0] for g in G]\r\n",
        "  widths = normalize(widths,max_val=max(widths),min_val=min(widths))\r\n",
        "  mat = np.zeros((1000,1000))\r\n",
        "\r\n",
        "  for i in range(1000):\r\n",
        "    for j in range(i,1000):\r\n",
        "      mat[i,j] = widths[i]*widths[j]\r\n",
        "\r\n",
        "  return np.maximum(mat, mat.T)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDc6FzcRf_5U",
        "outputId": "c691350e-950b-4a8b-a6e5-e076fc37aa1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = \"IMDB-BINARY\"\r\n",
        "classes = dp.get_dataset(dataset)\r\n",
        "G = tud_to_networkx(dataset)\r\n",
        "nkG = [nk.nxadapter.nx2nk(g) for g in G]\r\n",
        "\r\n",
        "def eval(matrices):\r\n",
        "  accuracy, std_10, std_100 = ke.kernel_svm_evaluation(matrices, classes, num_repetitions=num_reps, all_std=True)\r\n",
        "  print(accuracy, std_10, std_100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/IMDB-BINARY.zip\n",
            "Extracting /content/tudataset/tud_benchmark/datasets/IMDB-BINARY/IMDB-BINARY/IMDB-BINARY.zip\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwmivzKMe6yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6edd50d1-89dc-479b-d5e5-202dc8f4cec5"
      },
      "source": [
        "all_kernels = []\r\n",
        "num_reps = 10\r\n",
        "all_kernels.append(density_kernel(G))\r\n",
        "all_kernels.append(community_modularity_kernel(G))\r\n",
        "# print(accuracy, std_10, std_100) == (57.489999999999995, 1.2061923561356205, 5.356295361534873) # density, community\r\n",
        "\r\n",
        "eval(all_kernels)\r\n",
        "all_kernels.append(isomorphism_kernel(G))\r\n",
        "eval(all_kernels)\r\n",
        "# print(accuracy, std_10, std_100) == (59.03000000000001 1.8947559209565754 5.689384852512616) # density, community, isomorphic\r\n",
        "all_kernels.append(density_kernel(G))\r\n",
        "eval(all_kernels)\r\n",
        "# print(accuracy, std_10, std_100) == (62.17999999999999 1.0505236789335117 4.883400454601282) # density, community, isomorphic, eigencentrality\r\n",
        "all_kernels.append(eigencentrality_kernel(G))\r\n",
        "eval(all_kernels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "57.65 1.7979154596365206 5.409944546850734\n",
            "60.160000000000004 1.4752626884728015 5.830471679032495\n",
            "60.2 1.3266499161421599 5.073460357586328\n",
            "61.17 1.7641145087550296 5.748138829221159\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e-goLTWSNgu",
        "outputId": "a479fab6-f75b-4986-98f6-6fe978815317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eval([node_edge_kernel(G)])\r\n",
        "all_kernels.append(node_edge_kernel(G))\r\n",
        "eval(all_kernels)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.6 2.0985709423319476 6.415605972938176\n",
            "62.25 1.1200446419674528 4.85051543652837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA4YYfa-duzx",
        "outputId": "d7c563d4-e534-4ae0-ad2d-6f98da79943f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eval([treewidth_kernel(G)])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48.24 1.4759403781996072 5.312475882298196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPdcYpCrglTP"
      },
      "source": [
        "Experiments below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zSVWCRyd749",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe996248-c357-4504-f163-9d08d3afd718"
      },
      "source": [
        "all_matrices = []\r\n",
        "num_reps = 10\r\n",
        "use_labels, use_edge_labels = False, False\r\n",
        "\r\n",
        "# 1-WL kernel, number of iterations in [1:6].\r\n",
        "for i in range(1,6):\r\n",
        "    gm = kb.compute_wl_1_dense(dataset, i, use_labels, use_edge_labels)\r\n",
        "    # Cosine normalization.\r\n",
        "    gm = aux.normalize_gram_matrix(gm)\r\n",
        "    all_matrices.append(gm)\r\n",
        "    print(gm.shape)\r\n",
        "    print(gm[:5,:5])\r\n",
        "\r\n",
        "# accuracy is a mean of means of test accuracies\r\n",
        "accuracy, std_10, std_100 = ke.kernel_svm_evaluation(all_matrices, classes, num_repetitions=num_reps, all_std=True)\r\n",
        "print(accuracy, std_10, std_100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 1000)\n",
            "[[1.         0.09855258 0.08595703 0.22520897 0.13533299]\n",
            " [0.09855258 1.         0.07596444 0.2003595  0.04272494]\n",
            " [0.08595703 0.07596444 1.         0.21237361 0.05681146]\n",
            " [0.22520897 0.2003595  0.21237361 1.         0.10203572]\n",
            " [0.13533299 0.04272494 0.05681146 0.10203572 1.        ]]\n",
            "71.96000000000001 0.798999374217527 4.28933561288925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qkYqXZoA5UV",
        "outputId": "b585050b-4153-4ee0-ff89-1fe3e0158e78"
      },
      "source": [
        "G1 = nx.cycle_graph(6)\r\n",
        "G2 = nx.wheel_graph(7)\r\n",
        "nx.graph_edit_distance(G2, G1)\r\n",
        "\r\n",
        "import time\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "for g1 in range(5):\r\n",
        "  for g2 in range(5):\r\n",
        "    gen = nx.optimize_edit_paths(G[g1],G[g2],timeout=0.05)\r\n",
        "\r\n",
        "    try:\r\n",
        "      print(next(gen)[2])\r\n",
        "    except StopIteration:\r\n",
        "      pass\r\n",
        "      \r\n",
        "print(time.time() - start)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "98.0\n",
            "185.0\n",
            "97.0\n",
            "185.0\n",
            "91.0\n",
            "185.0\n",
            "180.0\n",
            "190.0\n",
            "105.0\n",
            "184.0\n",
            "102.0\n",
            "190.0\n",
            "94.0\n",
            "173.0\n",
            "190.0\n",
            "184.0\n",
            "93.0\n",
            "190.0\n",
            "92.0\n",
            "186.0\n",
            "44.0\n",
            "0.9439151287078857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2S5PwJmbBTjE",
        "outputId": "7e7ba34e-09f5-482b-cac6-ee8c43436fba"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "\r\n",
        "def is_symmetric(a, rtol=1e-05, atol=1e-08):\r\n",
        "    return numpy.allclose(a, a.T, rtol=rtol, atol=atol)\r\n",
        "\r\n",
        "dists = np.zeros((1000,1000))\r\n",
        "print(dists.shape)\r\n",
        "\r\n",
        "\r\n",
        "start = time.time()\r\n",
        "dists[0] = [oep(g) for g in G]\r\n",
        "print(time.time()-start)\r\n",
        "\r\n",
        "# for g1 in range(1,len(G)):\r\n",
        "#   print(g1)\r\n",
        "#   for g2 in range(g1,len(G)):\r\n",
        "#     if g1 != g2:\r\n",
        "#       gen = nx.optimize_edit_paths(G[g1],G[g2],timeout=0.05)\r\n",
        "\r\n",
        "#       try:\r\n",
        "#         dists[g1,g2] = next(gen)[2]\r\n",
        "#       except StopIteration:\r\n",
        "#         dists[g1,g2] = np.inf\r\n",
        "\r\n",
        "# print(is_symmetric(dists))\r\n",
        "# ke.kernel_svm_evaluation([dists], classes, num_repetitions=num_reps, all_std=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 1000)\n",
            "24.982826709747314\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}