{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit ('DM': conda)",
   "metadata": {
    "interpreter": {
     "hash": "e58acccd13c0b904097dad49c4f5d2c3238719687f6af75158b69e67c65fdc0e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from predecon import PreDeCon\n",
    "from elki_predecon_verification import elki_predecon, nmi_comparison\n",
    "\n",
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "base_path_testing = os.path.join('..', 'data')"
   ]
  },
  {
   "source": [
    "#### The comparison with ELKI uses the _unlabeled.csv files for clustering while for our own algorithm we load the labeled versions to compute the NMI. More high-dimensional datasets yielded strange/hard-to-analyze results even with the ELKI-algorithm so we stuck with simpler datasets and compared these instead."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clustering(ds, show_plots=False, save_nmi=False, **kwargs):\n",
    "    path = os.path.join(base_path_testing, ds, ds + '.csv')\n",
    "    data = np.loadtxt(path, delimiter=' ')\n",
    "    X, true_labels = data[:,:-1], data[:,-1]\n",
    "\n",
    "    predecon = PreDeCon(**kwargs)\n",
    "    predecon.fit(X)\n",
    "\n",
    "    if show_plots:\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "        ax[0].scatter(X[:, 0], X[:, 1], c=true_labels)\n",
    "        ax[0].set_title(\"True labels\")\n",
    "\n",
    "        ax[1].scatter(X[:,0], X[:,1], c=predecon.labels)\n",
    "        ax[1].set_title(\"PreDeCon labels\")\n",
    "\n",
    "    print(\"Clusters found (including noise):\",  len(set(predecon.labels)))\n",
    "    print(f\"Time: {predecon._performance['fit'] / 1000_000_000:>8.4f}s\")\n",
    "\n",
    "    path = os.path.join(base_path_testing, ds, ds + '_unlabeled.csv')\n",
    "    elki_labels = elki_predecon(path, X, **kwargs)\n",
    "    nmi_comparison(ds,elki_labels,predecon.labels,true_labels,save_nmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'multiple-gaussian-2d'\n",
    "clustering(dataset, show_plots=False, save_nmi=True, minPts=8, eps=1, delta=0.5, lambda_=2, kappa=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results of elki\n",
    "# display(Image(os.path.join(base_path_testing, dataset,'1__eps1__minPts8__delta0_5__kappa100__lambda2__legend.png')))\n",
    "# display(Image(os.path.join(base_path_testing, dataset,'1__eps1__minPts8__delta0_5__kappa100__lambda2.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'pov'\n",
    "clustering(dataset, show_plots=False, save_nmi=True, minPts=8, eps=0.7, delta=0.5, lambda_=2, kappa=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results of elki\n",
    "# display(Image(os.path.join(base_path_testing, dataset,'1__eps0_7__minPts8__delta0_5__kappa100__lambda2__legend.png')))\n",
    "# display(Image(os.path.join(base_path_testing, dataset,'1__eps0_7__minPts8__delta0_5__kappa100__lambda2.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mouse'\n",
    "clustering(dataset, show_plots=False, save_nmi=True, minPts=25, eps=0.725, delta=0.3, lambda_=2, kappa=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results of elki\n",
    "# display(Image(os.path.join(base_path_testing, dataset,'1__eps0_725__minPts25__delta0_3__kappa100__lambda2__legend.png')))\n",
    "# display(Image(os.path.join(base_path_testing, dataset,'1__eps0_725__minPts25__delta0_3__kappa100__lambda2.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'gamma-comet'\n",
    "clustering(dataset, show_plots=False, save_nmi=True, minPts=25, eps=0.725, delta=0.3, lambda_=2, kappa=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display results of elki\n",
    "# display(Image(os.path.join(base_path_testing, dataset,'1__eps0_5__minPts10__delta0_3__kappa100__lambda2__legend.png')))\n",
    "# display(Image(os.path.join(base_path_testing, dataset,'1__eps0_5__minPts10__delta0_3__kappa100__lambda2.png')))"
   ]
  },
  {
   "source": [
    "#### We also tested our implementation with the example data from exercise sheet 2. While this may not be very representative in itself, we think it might be useful to include it (since everyone has worked with this set in this course)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ex2'\n",
    "clustering(dataset, show_plots=False, save_nmi=True, minPts=3, eps=1, delta=0.25, lambda_=1, kappa=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('NMIs.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array([\n",
    "#     [0, 3],\n",
    "#     [1, 3],\n",
    "#     [2, 3],\n",
    "#     [3, 3],\n",
    "#     [4, 3],\n",
    "#     [5, 3],\n",
    "#     [6, 5],\n",
    "#     [6, 4],\n",
    "#     [6, 3],\n",
    "#     [6, 2],\n",
    "#     [6, 1],\n",
    "#     [6, 0]\n",
    "# ])\n",
    "\n",
    "# print(X, '\\n', X.shape, '\\n')\n",
    "\n",
    "# p2 = 1\n",
    "# p3 = 2\n",
    "# p6 = 5\n",
    "# p9 = 8\n",
    "\n",
    "# predecon = PreDeCon(minPts=3, eps=1, delta=0.25, lambda_=1, kappa=100)\n",
    "# predecon.fit(X)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(X[:,0], X[:,1], c=predecon.labels)\n",
    "\n",
    "# N_p3 = predecon._neighborhoods[p3]\n",
    "# print(\"p3:   \", X[p3])\n",
    "# print(\"N(p3):\", N_p3)\n",
    "\n",
    "# print(\"w_p3:\", predecon._subspace_preference_matrix[p3])\n",
    "# print(\"w_p6:\", predecon._subspace_preference_matrix[p6])\n",
    "\n",
    "# print(\"PDim for p3:\", predecon._subspace_preference_dimensionality[p3])\n",
    "# print(\"PDim for p6:\", predecon._subspace_preference_dimensionality[p6])\n",
    "\n",
    "# print(\"dist_pref(p6, p9) =\", predecon._similarity[p6, p9])\n",
    "\n",
    "# print(\"N_w for p3:\", predecon._pref_weighted_neighborhoods[p3], sep='\\n')\n",
    "# print(\"N_w for p6:\", predecon._pref_weighted_neighborhoods[p6], sep='\\n')\n",
    "\n",
    "# print(\"Is p3 a core point?\", predecon._core_points[p3])\n",
    "# print(\"Is p6 a core point?\", predecon._core_points[p6])\n",
    "\n",
    "# print(\"Is p2 directly preference weighted reachable from p3?\", \\\n",
    "#     p2 in predecon._directly_reachable_points[p3])\n",
    "# print(\"Is p6 directly preference weighted reachable from p3?\", \\\n",
    "#     p6 in predecon._directly_reachable_points[p3], '\\n')\n",
    "\n",
    "# print(\"Cluster labels:\", predecon.labels)\n",
    "# print(\"ID of p3:\", predecon.labels[p3])\n",
    "# print(\"p3 is noise: \", predecon.labels[p3] == predecon._NOISE)\n",
    "# print(\"ID of p6:\", predecon.labels[p6])\n",
    "# print(\"p6 is noise: \", predecon.labels[p6] == predecon._NOISE)"
   ]
  }
 ]
}