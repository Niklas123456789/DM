{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "uni.dm.ga",
   "display_name": "uni.dm.ga"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "import seaborn as sns\n",
    "from predecon import PreDeCon\n",
    "\n",
    "from IPython.display import Image\n",
    "import os\n",
    "import sys\n",
    "\n",
    "base_path_testing = os.path.join('..','algorithm_verification','datasets')\n",
    "base_path_imdb = os.path.join('..','graph_representations','without_labels')\n",
    "\n",
    "# csvs = []\n",
    "# for i in range(1,6):\n",
    "#     csvs.append(f'IMDB-BINARY_gram_matrix_wl{i}.csv')\n",
    "\n",
    "# PreDeCon(minPts=3, eps=1.0, delta=0.25, lambda_=1, kappa=100)"
   ]
  },
  {
   "source": [
    "#### The comparison with ELKI uses the _unlabeled.csv files for clustering while for our own algorithm we load the labeled versions to compute the, e.g. NMI. More high-dimensional datasets yielded very strange results even with the ELKI-algorithm so we stuck with simpler datasets and compared these instead. As one can see, the results of the ELKI-algorithm and our implementation match really well except for very few single data points between clusters.\n",
    "\n",
    "#### We also tested our implementation with the example data from exercise sheet 2. While this may not be very representative in itself, we think it might be useful to include it (since everyone has worked with this set in this course)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'multiple-gaussian-2d'\n",
    "X = np.loadtxt(os.path.join(base_path_testing, dataset, dataset + '.csv'), delimiter =' ')\n",
    "labs = 2\n",
    "X, lab = X[:,:labs], X[:,labs]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(x=X[:,0],y=X[:,1],c=lab)\n",
    "plt.show()\n",
    "\n",
    "predecon = PreDeCon(minPts=8, eps=1, delta=0.5, lambda_=2, kappa=100)\n",
    "predecon.fit(X)\n",
    "\n",
    "print(\"\\nClusterIDs of data-points:\", predecon.labels)\n",
    "print(\"\\nDifferent ClusterIDs:\", len(set(predecon.labels)))\n",
    "print(\"\\nNMI:\", NMI(lab,predecon.labels))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(x=X[:,0],y=X[:,1],c=predecon.labels)\n",
    "plt.show()\n",
    "\n",
    "# display results of elki\n",
    "print()\n",
    "display(Image(os.path.join(base_path_testing, dataset,'1__eps1__minPts8__delta0_5__kappa100__lambda2__legend.png')))\n",
    "display(Image(os.path.join(base_path_testing, dataset,'1__eps1__minPts8__delta0_5__kappa100__lambda2.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'pov'\n",
    "X = np.loadtxt(os.path.join(base_path_testing, dataset, dataset + '.csv'), delimiter =' ')\n",
    "labs = 2\n",
    "X, lab = X[:,:labs], X[:,labs]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(x=X[:,0],y=X[:,1],c=lab)\n",
    "plt.show()\n",
    "\n",
    "predecon = PreDeCon(minPts=8, eps=0.7, delta=0.5, lambda_=2, kappa=100)\n",
    "predecon.fit(X)\n",
    "\n",
    "print(\"\\nClusterIDs of data-points:\", predecon.labels)\n",
    "print(\"\\nDifferent ClusterIDs:\", len(set(predecon.labels)))\n",
    "print(\"\\nNMI:\", NMI(lab,predecon.labels))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(x=X[:,0],y=X[:,1],c=predecon.labels)\n",
    "plt.show()\n",
    "\n",
    "# display results of elki\n",
    "print()\n",
    "display(Image(os.path.join(base_path_testing, dataset,'1__eps0_7__minPts8__delta0_5__kappa100__lambda2__legend.png')))\n",
    "display(Image(os.path.join(base_path_testing, dataset,'1__eps0_7__minPts8__delta0_5__kappa100__lambda2.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work properly\n",
    "dataset = 'mouse'\n",
    "X = np.loadtxt(os.path.join(base_path_testing, dataset, dataset + '.csv'), delimiter =' ')\n",
    "labs = 2\n",
    "X, lab = X[:,:labs], X[:,labs]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(x=X[:,0],y=X[:,1],c=lab)\n",
    "plt.show()\n",
    "\n",
    "predecon = PreDeCon(minPts=25, eps=0.725, delta=0.3, lambda_=2, kappa=100)\n",
    "predecon.fit(X)\n",
    "\n",
    "print(\"\\nClusterIDs of data-points:\", predecon.labels)\n",
    "print(\"\\nDifferent ClusterIDs:\", len(set(predecon.labels)))\n",
    "print(\"\\nNMI:\", NMI(lab,predecon.labels))\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(x=X[:,0],y=X[:,1],c=predecon.labels)\n",
    "plt.show()\n",
    "\n",
    "# display results of elki\n",
    "print()\n",
    "display(Image(os.path.join(base_path_testing, dataset,'1__eps0_725__minPts25__delta0_3__kappa100__lambda2__legend.png')))\n",
    "display(Image(os.path.join(base_path_testing, dataset,'1__eps0_725__minPts25__delta0_3__kappa100__lambda2.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Dataset\n",
    "\n",
    "X = np.array([\n",
    "    [0, 3],\n",
    "    [1, 3], # p_2\n",
    "    [2, 3], # p_3\n",
    "    [3, 3],\n",
    "    [4, 3],\n",
    "    [5, 3], # p_6\n",
    "    [6, 5],\n",
    "    [6, 4],\n",
    "    [6, 3],\n",
    "    [6, 2],\n",
    "    [6, 1],\n",
    "    [6, 0]\n",
    "])\n",
    "print(X, '\\n', X.shape)\n",
    "\n",
    "predecon = PreDeCon()\n",
    "predecon.fit(X)\n",
    "\n",
    "p2 = X[1]\n",
    "p3 = X[2]\n",
    "p6 = X[5]\n",
    "p9 = X[8]\n",
    "\n",
    "N_p3 = predecon._neighborhood_of_point(p3)\n",
    "print(\"p3:   \", p3)\n",
    "print(\"N(p3):\", N_p3)\n",
    "\n",
    "var_A0 = predecon._variance_along_attribute(p3, 0)\n",
    "var_A1 = predecon._variance_along_attribute(p3, 1)\n",
    "print(\"VAR_A0 for p3's neighborhood:\", var_A0)\n",
    "print(\"VAR_A1 for p3's neighborhood:\", var_A1)\n",
    "\n",
    "print(\"w_p3:\", predecon._subspace_preference_vector(p3))\n",
    "print(\"w_p6:\", predecon._subspace_preference_vector(p6))\n",
    "\n",
    "print(\"PDim for p3:\", predecon._subspace_preference_dimensionality(p3))\n",
    "print(\"PDim for p6:\", predecon._subspace_preference_dimensionality(p6))\n",
    "\n",
    "dist = predecon._preference_weighted_similarity_measure\n",
    "print(\"dist(p6, p9) =\", dist(p6, p9))\n",
    "print(\"dist(p9, p6) =\", dist(p9, p6))\n",
    "\n",
    "dist_pref = predecon._general_preference_weighted_similarity_measure\n",
    "print(\"dist_pref(p6, p9) =\", dist_pref(p6, p9))\n",
    "\n",
    "print(\"N_w for p3:\", predecon._pref_neighborhood_of_point(p3), sep='\\n')\n",
    "print(\"N_w for p6:\", predecon._pref_neighborhood_of_point(p6), sep='\\n')\n",
    "\n",
    "print(\"Is p3 a core point?\", predecon._is_core_point(p3))\n",
    "print(\"Is p6 a core point?\", predecon._is_core_point(p6))\n",
    "\n",
    "print(\"Is p2 directly preference weighted reachable from p3?\", predecon._is_directly_preference_weighted_reachable(p3,p2))\n",
    "print(\"Is p6 directly preference weighted reachable from p3?\", predecon._is_directly_preference_weighted_reachable(p3,p6))\n",
    "\n",
    "print(\"\\nClusterIDs of data-points: \\n\", predecon._cluster_of_points)\n",
    "print(\"\\nClusterIDs of data-points:\", predecon.labels)\n",
    "print(\"ID of p3:\", predecon._cluster_of_points[p3.tobytes()])\n",
    "print(\"ID of p3:\", predecon.labels[2])\n",
    "print(\"p3 is noise: \", predecon._is_noise_point(p3))\n",
    "print(\"ID of p6:\", predecon._cluster_of_points[p6.tobytes()])\n",
    "print(\"ID of p6:\", predecon.labels[5])\n",
    "print(\"p6 is noise: \", predecon._is_noise_point(p6))\n",
    "\n",
    "# predecon._is_noise_point(np.array([7,0])) raises KeyError\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "ax.scatter(x=X[:,0],y=X[:,1],c=predecon.labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}