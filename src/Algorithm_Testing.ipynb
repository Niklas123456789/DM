{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "uni.dm.ga",
   "display_name": "uni.dm.ga"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from algorithm_test_utils import algo_test, base_path_testing, base_path_imdb\n",
    "\n",
    "# csvs = []\n",
    "# for i in range(1,6):\n",
    "#     csvs.append(f'IMDB-BINARY_gram_matrix_wl{i}.csv')\n",
    "\n",
    "# PreDeCon(minPts=3, eps=1.0, delta=0.25, lambda_=1, kappa=100)"
   ]
  },
  {
   "source": [
    "#### The comparison with ELKI uses the _unlabeled.csv files for clustering while for our own algorithm we load the labeled versions to compute the, e.g. NMI. More high-dimensional datasets yielded strange/hard-to-visually-analyse results even with the ELKI-algorithm so we stuck with simpler datasets and compared those instead. As one can see, the results of the ELKI-algorithm and our implementation match really well except for very few single data points between clusters, where ELKI seems to perform slightly better.\n",
    "\n",
    "#### ELKI is much faster in computing the clusterings. Our implementation is purely sequential while ELKI probably parallelizes its computations.\n",
    "\n",
    "#### We also tested our implementation with the example data from exercise sheet 2. While this may not be very representative in itself, we think it might be useful to include it (since everyone has worked with this set in this course)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_test(dataset='multiple-gaussian-2d', labelcolumn=2, minPts=8, eps=1, delta=0.5, lambda_=2, kappa=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_test(dataset='pov', labelcolumn=2, minPts=8, eps=0.7, delta=0.5, lambda_=2, kappa=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work properly\n",
    "algo_test(dataset='mouse', labelcolumn=2, minPts=24, eps=0.73, delta=0.5, lambda_=2, kappa=100, show_elki=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_test(dataset='gamma-comet', labelcolumn=2, minPts=10, eps=0.5, delta=0.3, lambda_=2, kappa=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 2 Dataset\n",
    "algo_test(dataset='ex2', labelcolumn=2, minPts=3, eps=1.0, delta=0.25, lambda_=1, kappa=100, show_elki=False)"
   ]
  }
 ]
}