{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "uni.dm.ga",
   "display_name": "uni.dm.ga"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "sys.path.append('../tudataset/tud_benchmark/')\n",
    "\n",
    "from predecon import PreDeCon\n",
    "from scipy.sparse import linalg\n",
    "from pathlib import Path\n",
    "from auxiliarymethods.auxiliary_methods import normalize_feature_vector as normalize_v\n",
    "from auxiliarymethods.auxiliary_methods import normalize_gram_matrix as normalize_m\n",
    "from sources.utility_functions import load_sparse as load_v\n",
    "from sources.utility_functions import load_csv as load_m\n",
    "from sources.dimensionality_reduction import truncatedSVD as svd\n",
    "from sources.dimensionality_reduction import kernelPCA as pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predecon_config(kernel, format, dims, minPts, eps, delta, lambda_, kappa):\n",
    "    imdb = Path('../graph_representations/without_labels/')\n",
    "    vector_path = imdb / f'IMDB-BINARY_vectors_{kernel}.npz'\n",
    "    matrix_path = imdb / f'IMDB-BINARY_gram_matrix_{kernel}.csv'\n",
    "\n",
    "    if format == 'vector':\n",
    "        vectors = normalize_v(load_v(vector_path))\n",
    "        data = svd(vectors, dims)\n",
    "    else:\n",
    "        matrix = normalize_m(load_m(matrix_path))\n",
    "        data = pca(matrix, dims)\n",
    "    \n",
    "    predecon = PreDeCon(minPts=minPts, eps=eps, delta=delta, lambda_=lambda_, kappa=kappa)\n",
    "    predecon.fit(data)\n",
    "    return predecon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Clusters found: {1, 2, -1}\n"
     ]
    }
   ],
   "source": [
    "kernel = 'wl3'\n",
    "format = 'matrix'\n",
    "dims = 50\n",
    "\n",
    "predecon = predecon_config(kernel, format, dims, 25, 0.75, 1, 50, 10)\n",
    "print(\"Clusters found:\", set(predecon.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kernels = ['wl1', 'wl2', 'wl3', 'wl4', 'wl5', 'graphlet', 'shortestpath']\n",
    "all_formats = ['vector', 'matrix']\n",
    "all_dims    = [50, 100]\n",
    "\n",
    "all_minPts  = [5, 10, 25, 100]\n",
    "all_eps     = [0.25, 0.75, 2, 5, 50]\n",
    "all_deltas  = [0.1, 0.25, 0.5, 1, 5, 20]\n",
    "all_lambdas = [2, 5, 15, 50]\n",
    "all_kappas  = [10, 100, 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Trial 0: No clusterings found\n",
      "Trial 1: No clusterings found\n",
      "Trial 2: No clusterings found\n",
      "Trial 3: No clusterings found\n",
      "Trial 4: No clusterings found\n",
      "Trial 5: No clusterings found\n",
      "Trial 6: No clusterings found\n",
      "Trial 7: No clusterings found\n",
      "Trial 8: No clusterings found\n",
      "Trial 9: \n",
      "   shortestpath matrix 50\n",
      "   5 0.25 0.5 50 100\n",
      "   {1, 2, 3, 4, 5, 6, -1}\n",
      "  time: 2.2098s\n"
     ]
    }
   ],
   "source": [
    "# randomized parameter space search\n",
    "\n",
    "num_trials = 10\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    print(f\"Trial {trial}: \", end='')\n",
    "\n",
    "    kernel  = random.choice(all_kernels)\n",
    "    format  = random.choice(all_formats)\n",
    "    dims    = random.choice(all_dims)\n",
    "\n",
    "    minPts  = random.choice(all_minPts)\n",
    "    eps     = random.choice(all_eps)\n",
    "    delta   = random.choice(all_deltas)\n",
    "    lambda_ = random.choice(all_lambdas)\n",
    "    kappa  = random.choice(all_kappas)\n",
    "\n",
    "    predecon = predecon_config(kernel=kernel, format=format, dims=dims, \\\n",
    "               minPts=minPts, eps=eps, delta=delta, lambda_=lambda_, kappa=kappa)\n",
    "    \n",
    "    if len(set(predecon.labels)) > 1:\n",
    "        print(\"\\n  \", kernel, format, dims)\n",
    "        print(\"  \", minPts, eps, delta, lambda_, kappa)\n",
    "        print(\"  \", set(predecon.labels))\n",
    "        print(f\"  time: {predecon._performance['fit'] / 1000_000_000:.4f}s\")\n",
    "    else:\n",
    "        print(\"No clusterings found\")\n",
    "    \n",
    "    if predecon._performance['fit'] > 60 * 1000_000_000:\n",
    "        print(\"  Took too longâ€¦\")\n",
    "        print(\"  \", kernel, format, dims)\n",
    "        print(\"  \", minPts, eps, delta, lambda_, kappa)\n",
    "        print(f\"  time: {predecon._performance['fit'] / 1000_000_000:.4f}s\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}